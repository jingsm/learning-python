{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Inception-v3 모델을 이용한 Image Classification\n",
    "\n",
    "# 절대 임포트 설정\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# 필요한 라이브러리들을 임포트\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classify_image_graph_def.pb:\n",
    "#   GraphDef protocol buffer의 이진 표현\n",
    "# imagenet_synset_to_human_label_map.txt:\n",
    "#   synset ID를 인간이 읽을수 있는 문자로 맵핑\n",
    "# imagenet_2012_challenge_label_map_proto.pbtxt:\n",
    "#   protocol buffer의 문자 표현을 synset ID의 레이블로 맵핑\n",
    "\n",
    "# Inception-v3 모델을 다운로드 받을 경로를 설정\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'model_dir', '/tmp/imagenet',\n",
    "    \"\"\"Path to classify_image_graph_def.pb, \"\"\"\n",
    "    \"\"\"imagenet_synset_to_human_label_map.txt, and \"\"\"\n",
    "    \"\"\"imagenet_2012_challenge_label_map_proto.pbtxt.\"\"\")\n",
    "# 읽을 이미지 파일의 경로를 설정\n",
    "tf.app.flags.DEFINE_string('image_file', '',\n",
    "                           \"\"\"Absolute path to image file.\"\"\")\n",
    "# 이미지의 추론결과를 몇개까지 표시할 것인지 설정\n",
    "tf.app.flags.DEFINE_integer('num_top_predictions', 5,\n",
    "                            \"\"\"Display this many predictions.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inception-v3 모델을 다운로드할 URL 주소\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/imagenet'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 정수 형태의 node ID를 인간이 이해할 수 있는 레이블로 변환\n",
    "class NodeLookup(object):\n",
    "\n",
    "  def __init__(self,\n",
    "               label_lookup_path=None,\n",
    "               uid_lookup_path=None):\n",
    "    if not label_lookup_path:\n",
    "      label_lookup_path = os.path.join(\n",
    "          FLAGS.model_dir, 'imagenet_2012_challenge_label_map_proto.pbtxt')\n",
    "    if not uid_lookup_path:\n",
    "      uid_lookup_path = os.path.join(\n",
    "          FLAGS.model_dir, 'imagenet_synset_to_human_label_map.txt')\n",
    "    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "  def load(self, label_lookup_path, uid_lookup_path):\n",
    "    \"\"\"각각의 softmax node에 대해 인간이 읽을 수 있는 영어 단어를 로드 함.\n",
    "    Args:\n",
    "      label_lookup_path: 정수 node ID에 대한 문자 UID.\n",
    "      uid_lookup_path: 인간이 읽을 수 있는 문자에 대한 문자 UID.\n",
    "    Returns:\n",
    "      정수 node ID로부터 인간이 읽을 수 있는 문자에 대한 dict.\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(uid_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
    "    if not tf.gfile.Exists(label_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
    "\n",
    "    #  문자 UID로부터 인간이 읽을 수 있는 문자로의 맵핑을 로드함.\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "    uid_to_human = {}\n",
    "    p = re.compile(r'[n\\d]*[ \\S,]*')\n",
    "    for line in proto_as_ascii_lines:\n",
    "      parsed_items = p.findall(line)\n",
    "      uid = parsed_items[0]\n",
    "      human_string = parsed_items[2]\n",
    "      uid_to_human[uid] = human_string\n",
    "\n",
    "    # 문자 UID로부터 정수 node ID에 대한 맵핑을 로드함.\n",
    "    node_id_to_uid = {}\n",
    "    proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "    for line in proto_as_ascii:\n",
    "      if line.startswith('  target_class:'):\n",
    "        target_class = int(line.split(': ')[1])\n",
    "      if line.startswith('  target_class_string:'):\n",
    "        target_class_string = line.split(': ')[1]\n",
    "        node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "\n",
    "    # 마지막으로 정수 node ID로부터 인간이 읽을 수 있는 문자로의 맵핑을 로드함.\n",
    "    node_id_to_name = {}\n",
    "    for key, val in node_id_to_uid.items():\n",
    "      if val not in uid_to_human:\n",
    "        tf.logging.fatal('Failed to locate: %s', val)\n",
    "      name = uid_to_human[val]\n",
    "      node_id_to_name[key] = name\n",
    "\n",
    "    return node_id_to_name\n",
    "\n",
    "  def id_to_string(self, node_id):\n",
    "    if node_id not in self.node_lookup:\n",
    "      return ''\n",
    "    return self.node_lookup[node_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "  \"\"\"저장된 GraphDef 파일로부터 그래프를 생성하고 저장된 값을 리턴함.\"\"\"\n",
    "  # Creates graph from saved graph_def.pb.\n",
    "  with tf.gfile.FastGFile(os.path.join(\n",
    "      FLAGS.model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "\n",
    "def run_inference_on_image(image):\n",
    "  \"\"\"이미지에 대한 추론을 실행\n",
    "  Args:\n",
    "    image: 이미지 파일 이름.\n",
    "  Returns:\n",
    "    없음(Nothing)\n",
    "  \"\"\"\n",
    "  if not tf.gfile.Exists(image):\n",
    "    tf.logging.fatal('File does not exist %s', image)\n",
    "  image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "\n",
    "  # 저장된 GraphDef로부터 그래프 생성\n",
    "  create_graph()\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    # 몇가지 유용한 텐서들:\n",
    "    # 'softmax:0': 1000개의 레이블에 대한 정규화된 예측결과값(normalized prediction)을 포함하고 있는 텐서   \n",
    "    # 'pool_3:0': 2048개의 이미지에 대한 float 묘사를 포함하고 있는 next-to-last layer를 포함하고 있는 텐서\n",
    "    # 'DecodeJpeg/contents:0': 제공된 이미지의 JPEG 인코딩 문자를 포함하고 있는 텐서\n",
    "\n",
    "    # image_data를 인풋으로 graph에 집어넣고 softmax tesnor를 실행한다.\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    predictions = sess.run(softmax_tensor,\n",
    "                           {'DecodeJpeg/contents:0': image_data})\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "    # node ID --> 영어 단어 lookup을 생성한다.\n",
    "    node_lookup = NodeLookup()\n",
    "\n",
    "    top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n",
    "    for node_id in top_k:\n",
    "      human_string = node_lookup.id_to_string(node_id)\n",
    "      score = predictions[node_id]\n",
    "      print('%s (score = %.5f)' % (human_string, score))\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract model tar file.\"\"\"\n",
    "  dest_directory = FLAGS.model_dir\n",
    "  if not os.path.exists(dest_directory):\n",
    "  \tos.makedirs(dest_directory)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
    "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "  \n",
    "def main(argv=None):\n",
    "  # Inception-v3 모델을 다운로드하고 압축을 푼다.\n",
    "  maybe_download_and_extract()\n",
    "  # 인풋으로 입력할 이미지를 설정한다.\n",
    "  \"\"\"\n",
    "  image = (FLAGS.image_file if FLAGS.image_file else\n",
    "           os.path.join(FLAGS.model_dir, 'cropped_panda.jpg'))\n",
    "  # 고양이 이미지에 대해 prediction\n",
    "  \"\"\"\n",
    "  #imageName = 'cropped_panda.jpg'\n",
    "  imageName = 'funny_cat.jpg'\n",
    "  image = (FLAGS.image_file if FLAGS.image_file else\n",
    "           os.path.join(FLAGS.model_dir, imageName))\n",
    "  # 인풋으로 입력되는 이미지에 대한 추론을 실행한다.\n",
    "  run_inference_on_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabby, tabby cat (score = 0.50205)\n",
      "Egyptian cat (score = 0.27003)\n",
      "tiger cat (score = 0.06898)\n",
      "shower cap (score = 0.00189)\n",
      "terrapin (score = 0.00160)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programs\\python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
